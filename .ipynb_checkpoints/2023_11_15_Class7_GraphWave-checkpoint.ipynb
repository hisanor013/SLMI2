{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blogcatalog', 'homosapiens', 'wikipos', 'enron', 'unvote', 'untrade', 'uslegis_net', 'uslegis_net_small_dyn', 'uslegis_net_dyn', 'uslegis_hyp_dyn', 'contacts', 'dawn_net', 'dawn_hyp', 'ndc_net', 'ndc_hyp', 'coauth_dblp_net', 'coauth_dblp_hyp', 'wiod2016', 'wiod2013', 'wiodlong', 'eth', 'bitcoinalpha', 'bitcoinotc', 'uscourt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:53:51.052444: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-18 15:53:51.277507: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-18 15:53:52.017244: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-11-18 15:53:52.017324: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-11-18 15:53:52.017336: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are going to use: enron\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:53:53.063457: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-18 15:53:54.637330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 220 MB memory:  -> device: 0, name: Quadro P6000, pci bus id: 0000:37:00.0, compute capability: 6.1\n",
      "2023-11-18 15:53:54.638660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 23382 MB memory:  -> device: 1, name: Quadro P6000, pci bus id: 0000:86:00.0, compute capability: 6.1\n",
      "2023-11-18 15:53:54.684922: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 220.44M (231145472 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    }
   ],
   "source": [
    "# From the repository\n",
    "from util import *\n",
    "from read_data import *\n",
    "data_names = list(name2file_name.keys())\n",
    "print(data_names)\n",
    "\n",
    "# Basic modules\n",
    "import os\n",
    "import glob\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "import stellargraph as sg\n",
    "from stellargraph import StellarGraph, datasets\n",
    "from stellargraph.datasets import IAEnronEmployees\n",
    "from stellargraph.data import EdgeSplitter\n",
    "from stellargraph import IndexedArray\n",
    "\n",
    "# sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from stellargraph.data import BiasedRandomWalk\n",
    "from gensim.models import Word2Vec\n",
    "from stellargraph.mapper import FullBatchLinkGenerator, FullBatchNodeGenerator\n",
    "from stellargraph.layer import GCN, LinkEmbedding\n",
    "from stellargraph.data import BiasedRandomWalk\n",
    "from stellargraph.data import UnsupervisedSampler\n",
    "from stellargraph.mapper import Node2VecLinkGenerator, Node2VecNodeGenerator\n",
    "from stellargraph.layer import Node2Vec, link_classification\n",
    "from tensorflow import keras\n",
    "\n",
    "from stellargraph.mapper import GraphWaveGenerator\n",
    "from stellargraph import StellarGraph\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.sparse.linalg import eigs\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "# import module\n",
    "\n",
    "#name = \"wiod2016\"\n",
    "name = data_names[3]\n",
    "print(\"We are going to use: \" + name)\n",
    "# Enable original_format to use the format as originally provided\n",
    "data_dict = get_data(name,original_format=False)\n",
    "data_dict.keys()\n",
    "#df_nodes = data_dict[\"df_nodes\"]\n",
    "df_edges = data_dict[\"df_edges\"]\n",
    "\n",
    "df_edges = df_edges[[\"source\",\"target\"]].drop_duplicates()\n",
    "cond = df_edges[\"source\"] != df_edges[\"target\"]\n",
    "df_edges = df_edges.loc[cond].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Stellar Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 182, Edges: 3007\n",
      "\n",
      " Node types:\n",
      "  default: [182]\n",
      "    Features: none\n",
      "    Edge types: default-default->default\n",
      "\n",
      " Edge types:\n",
      "    default-default->default: [3007]\n",
      "        Weights: all 1 (default)\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "graph = StellarGraph(edges=df_edges)\n",
    "print(graph.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graph_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m scales \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m]\n\u001b[1;32m      5\u001b[0m generator \u001b[38;5;241m=\u001b[39m GraphWaveGenerator(graph, scales\u001b[38;5;241m=\u001b[39mscales, degree\u001b[38;5;241m=\u001b[39mdegree)\n\u001b[1;32m      6\u001b[0m embeddings_dataset \u001b[38;5;241m=\u001b[39m generator\u001b[38;5;241m.\u001b[39mflow(\n\u001b[0;32m----> 7\u001b[0m     node_ids\u001b[38;5;241m=\u001b[39m\u001b[43mgraph_train\u001b[49m\u001b[38;5;241m.\u001b[39mnodes(), sample_points\u001b[38;5;241m=\u001b[39msample_points, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m embeddings_dataset]\n\u001b[1;32m     11\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(embeddings)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'graph_train' is not defined"
     ]
    }
   ],
   "source": [
    "sample_points = np.linspace(0, 100, 50).astype(np.float32)\n",
    "degree = 20\n",
    "scales = [5, 10]\n",
    "\n",
    "generator = GraphWaveGenerator(graph, scales=scales, degree=degree)\n",
    "embeddings_dataset = generator.flow(\n",
    "    node_ids=graph.nodes(), sample_points=sample_points, batch_size=1, repeat=False\n",
    ")\n",
    "\n",
    "embeddings = [x.numpy() for x in embeddings_dataset]\n",
    "X = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = TSNE  # or PCA\n",
    "trans = transform(n_components=2)\n",
    "X_reduced = trans.fit_transform(X)\n",
    "X_reduced.shape\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.scatter(\n",
    "    X_reduced[:, 0],\n",
    "    X_reduced[:, 1],\n",
    "    #c=node_subjects.astype(\"category\").cat.codes,\n",
    "    #cmap=\"jet\",\n",
    "    color=\"skyblue\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "random.seed(456)\n",
    "for i, text in enumerate(nodes ):\n",
    "    if (nodes[i] == 83):\n",
    "        plt.annotate(nodes[i], (X_reduced[i, 0], X_reduced[i, 1]), \n",
    "                 textcoords=\"offset points\", xytext=(0,10), ha='center',size=12)\n",
    "    elif (nodes[i] == 106):\n",
    "        plt.annotate(nodes[i], (X_reduced[i, 0], X_reduced[i, 1]), \n",
    "                 textcoords=\"offset points\", xytext=(0,-10), ha='center',size=12)\n",
    "    elif (nodes[i] == 154):\n",
    "        plt.annotate(nodes[i], (X_reduced[i, 0], X_reduced[i, 1]), \n",
    "                 textcoords=\"offset points\", xytext=(0,-10), ha='center',size=12)\n",
    "    else:\n",
    "        if random.uniform(0,1) < 0.06:\n",
    "        \n",
    "            plt.annotate(nodes[i], (X_reduced[i, 0], X_reduced[i, 1]), \n",
    "                 textcoords=\"offset points\", xytext=(0,10), ha='center',size=12)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
