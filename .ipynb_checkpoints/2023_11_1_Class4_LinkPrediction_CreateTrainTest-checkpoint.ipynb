{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eef2269",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8b8046a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blogcatalog', 'homosapiens', 'wikipos', 'enron', 'unvote', 'untrade', 'uslegis_net', 'uslegis_net_small_dyn', 'uslegis_net_dyn', 'uslegis_hyp_dyn', 'contacts', 'dawn_net', 'dawn_hyp', 'ndc_net', 'ndc_hyp', 'coauth_dblp_net', 'coauth_dblp_hyp', 'wiod2016', 'wiod2013', 'wiodlong', 'eth', 'bitcoinalpha', 'bitcoinotc', 'uscourt']\n",
      "We are going to use: enron\n"
     ]
    }
   ],
   "source": [
    "# From the repository\n",
    "from util import *\n",
    "from read_data import *\n",
    "data_names = list(name2file_name.keys())\n",
    "print(data_names)\n",
    "\n",
    "# Basic modules\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "#name = \"wiod2016\"\n",
    "name = data_names[3]\n",
    "print(\"We are going to use: \" + name)\n",
    "# Enable original_format to use the format as originally provided\n",
    "data_dict = get_data(name,original_format=False)\n",
    "data_dict.keys()\n",
    "#df_nodes = data_dict[\"df_nodes\"]\n",
    "df_edges = data_dict[\"df_edges\"]\n",
    "\n",
    "# Add weights (no peculiar meaning)\n",
    "# Remove self-loops \n",
    "df_edges[\"weight\"] = 1.0\n",
    "cond = df_edges[\"source\"] != df_edges[\"target\"]\n",
    "df_edges = df_edges.loc[cond].copy()\n",
    "df_edges = df_edges[[\"source\",\"target\",\"weight\"]].copy()\n",
    "df_edges.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545889fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a26189b8",
   "metadata": {},
   "source": [
    "# Set seed number and number of negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a4e1600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed number => to get identical result\n",
    "seed_num = 12345\n",
    "\n",
    "# This is the number of negative samples we make against the positve ones\n",
    "num_neg = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d817eff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca462ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f439f96",
   "metadata": {},
   "source": [
    "# Making undirected edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15820691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of original edges:3007\n",
      "Number of unique undirected edges:2097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42899/3747320424.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_edges_2[\"source\"] = df_edges_2[\"source\"].astype(str)\n",
      "/tmp/ipykernel_42899/3747320424.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_edges_2[\"target\"] = df_edges_2[\"target\"].astype(str)\n"
     ]
    }
   ],
   "source": [
    "undirected = \"True\"\n",
    "if undirected == \"True\":\n",
    "    out = []\n",
    "    for i in range(len(df_edges)):\n",
    "        if df_edges[\"source\"].iloc[i] < df_edges[\"target\"].iloc[i]:\n",
    "            out.append([\n",
    "            df_edges[\"source\"].iloc[i],df_edges[\"target\"].iloc[i],df_edges[\"weight\"].iloc[i]])\n",
    "        else:\n",
    "            out.append([\n",
    "            df_edges[\"target\"].iloc[i],df_edges[\"source\"].iloc[i],df_edges[\"weight\"].iloc[i]])\n",
    "\n",
    "    df_edges = pd.DataFrame(out)\n",
    "    df_edges.columns = [\"source\",\"target\",\"weight\"]\n",
    "    \n",
    "df_edges_2 = df_edges.drop_duplicates(subset=[\"source\",\"target\"],keep='first')\n",
    "\n",
    "df_edges_2[\"source\"] = df_edges_2[\"source\"].astype(str)\n",
    "df_edges_2[\"target\"] = df_edges_2[\"target\"].astype(str)\n",
    "\n",
    "print(\"Number of original edges:\" + str(len(df_edges)))\n",
    "print(\"Number of unique undirected edges:\" + str(len(df_edges_2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f94ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7d035b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a768684",
   "metadata": {},
   "source": [
    "# Create Train and Test\n",
    "# We make sure that there is at least one edge for all nodes in train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02cedc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 70.3 ms, sys: 2.9 ms, total: 73.2 ms\n",
      "Wall time: 71.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "random.seed(seed_num)\n",
    "node2cnt = dict()\n",
    "index_test = []\n",
    "index_vali = []\n",
    "index_train = []\n",
    "for i in range(len(df_edges_2)):\n",
    "    \n",
    "    source = df_edges_2[\"source\"].iloc[i]\n",
    "    target = df_edges_2[\"target\"].iloc[i]\n",
    "    \n",
    "    if source in node2cnt and target in node2cnt:\n",
    "        if random.uniform(0,1) < 0.415:\n",
    "            if random.uniform(0,1) < 0.5:\n",
    "                index_test.append(i)\n",
    "            else:\n",
    "                index_vali.append(i)        \n",
    "        else:\n",
    "            index_train.append(i)\n",
    "        \n",
    "    else:\n",
    "        index_train.append(i)\n",
    "        if source in node2cnt:\n",
    "            node2cnt[source] += 1\n",
    "        else:\n",
    "            node2cnt.update({source:1})\n",
    "        if target in node2cnt:\n",
    "            node2cnt[target] += 1\n",
    "        else:\n",
    "            node2cnt.update({target:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "818480d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6003814973772056\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(index_train) / (len(index_train) + len(index_test) + len(index_vali)))\n",
    "print(len(index_train) + len(index_test) + len(index_vali) == len(df_edges_2))\n",
    "\n",
    "df_train = df_edges_2.iloc[index_train].copy()\n",
    "df_valid = df_edges_2.iloc[index_vali].copy()\n",
    "df_test = df_edges_2.iloc[index_test].copy()\n",
    "\n",
    "df_node2cnt = pd.DataFrame(node2cnt.items())\n",
    "df_node2cnt.columns = [\"node\",\"cnt\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf0c364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03270a19",
   "metadata": {},
   "source": [
    "# Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ac28282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 198 ms, sys: 2.21 ms, total: 200 ms\n",
      "Wall time: 200 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pair_train = dict()\n",
    "pos_pair = dict()\n",
    "pos_pair_test = dict()\n",
    "for i in range(len(df_train)):\n",
    "    pair_a = df_train[\"source\"].iloc[i] + \",\" + df_train[\"target\"].iloc[i]\n",
    "    pair_b = df_train[\"target\"].iloc[i] + \",\" + df_train[\"source\"].iloc[i]\n",
    "    pair_train.update({pair_a:1})\n",
    "    pair_train.update({pair_b:1}) \n",
    "    pos_pair.update({pair_a:1})\n",
    "    if df_train[\"source\"].iloc[i] == df_train[\"target\"].iloc[i]:\n",
    "        print(\"Error 1: self loop\" )\n",
    "        \n",
    "for i in range(len(df_valid)):\n",
    "    pair_a = df_valid[\"source\"].iloc[i] + \",\" + df_valid[\"target\"].iloc[i]\n",
    "    pair_b = df_valid[\"target\"].iloc[i] + \",\" + df_valid[\"source\"].iloc[i]\n",
    "    pos_pair.update({pair_a:1})\n",
    "    pos_pair_test.update({pair_a:1})\n",
    "    if pair_a in pair_train:\n",
    "        print(\"Error 2: Found same edge in train (validation)\")\n",
    "    if pair_b in pair_train:\n",
    "        print(\"Error 3: Found same edge in train (validation)\")\n",
    "    if df_valid[\"source\"].iloc[i] == df_valid[\"target\"].iloc[i]:\n",
    "        print(\"Error 1: self loop\" )\n",
    "        \n",
    "for i in range(len(df_test)):\n",
    "    pair_a = df_test[\"source\"].iloc[i] + \",\" + df_test[\"target\"].iloc[i]\n",
    "    pair_b = df_test[\"target\"].iloc[i] + \",\" + df_test[\"source\"].iloc[i]\n",
    "    pos_pair.update({pair_a:1})\n",
    "    \n",
    "    pos_pair_test.update({pair_a:1})\n",
    "    if pair_a in pair_train:\n",
    "        print(\"Error 4: Found same edge in train (test)\")\n",
    "    if pair_b in pair_train:\n",
    "        print(\"Error 5: Found same edge in train (test)\")\n",
    "    if df_test[\"source\"].iloc[i] == df_test[\"target\"].iloc[i]:\n",
    "        print(\"Error 1: self loop\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397bd983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d25ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "376adae3",
   "metadata": {},
   "source": [
    "# Create Negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7f145b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished train_neg\n",
      "Finished valid_neg\n",
      "Finished test_neg\n",
      "CPU times: user 3.07 s, sys: 439 ms, total: 3.51 s\n",
      "Wall time: 2.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "random.seed(seed_num)\n",
    "out_train_neg = []\n",
    "neg_pair = dict()\n",
    "while len(out_train_neg) < num_neg*len(df_train):\n",
    "    neg_s = df_node2cnt.sample(1)[\"node\"].iloc[0]\n",
    "    neg_t = df_node2cnt.sample(1)[\"node\"].iloc[0]\n",
    "    tmp_pair_a = neg_s + \",\" + neg_t\n",
    "    tmp_pair_b = neg_t + \",\" + neg_s\n",
    "    if neg_s != neg_t:\n",
    "        if (tmp_pair_a not in pos_pair) &  (tmp_pair_b not in pos_pair):\n",
    "            if (tmp_pair_a not in pos_pair_test) &  (tmp_pair_b not in pos_pair_test):\n",
    "                if (tmp_pair_a not in neg_pair) & (tmp_pair_b not in neg_pair):\n",
    "                    out_train_neg.append([neg_s,neg_t])\n",
    "                    out_train_neg.append([neg_t,neg_s])\n",
    "                    neg_pair.update({tmp_pair_a:1})\n",
    "                    neg_pair.update({tmp_pair_b:1})\n",
    "print(\"Finished train_neg\")\n",
    "    \n",
    "out_valid_neg = []\n",
    "while len(out_valid_neg) < num_neg*len(df_valid):\n",
    "    neg_s = df_node2cnt.sample(1)[\"node\"].iloc[0]\n",
    "    neg_t = df_node2cnt.sample(1)[\"node\"].iloc[0]\n",
    "    tmp_pair_a = neg_s + \",\" + neg_t\n",
    "    tmp_pair_b = neg_t + \",\" + neg_s\n",
    "    if neg_s != neg_t:\n",
    "        if (tmp_pair_a not in pos_pair) &  (tmp_pair_b not in pos_pair):\n",
    "            if (tmp_pair_a not in pos_pair_test) &  (tmp_pair_b not in pos_pair_test):\n",
    "                if (tmp_pair_a not in neg_pair) & (tmp_pair_b not in neg_pair):\n",
    "                    out_valid_neg.append([neg_s,neg_t])\n",
    "                    out_valid_neg.append([neg_t,neg_s])\n",
    "                    neg_pair.update({tmp_pair_a:1})\n",
    "                    neg_pair.update({tmp_pair_b:1})\n",
    "print(\"Finished valid_neg\")\n",
    "    \n",
    "out_test_neg = []\n",
    "while len(out_test_neg) < num_neg*len(df_test):\n",
    "    neg_s = df_node2cnt.sample(1)[\"node\"].iloc[0]\n",
    "    neg_t = df_node2cnt.sample(1)[\"node\"].iloc[0]\n",
    "    tmp_pair_a = neg_s + \",\" + neg_t\n",
    "    tmp_pair_b = neg_t + \",\" + neg_s\n",
    "    if neg_s != neg_t:\n",
    "        if (tmp_pair_a not in pos_pair) &  (tmp_pair_b not in pos_pair):\n",
    "            if (tmp_pair_a not in pos_pair_test) &  (tmp_pair_b not in pos_pair_test):\n",
    "                if (tmp_pair_a not in neg_pair) & (tmp_pair_b not in neg_pair):\n",
    "                    out_test_neg.append([neg_s,neg_t])\n",
    "                    out_test_neg.append([neg_t,neg_s])\n",
    "                    neg_pair.update({tmp_pair_a:1})\n",
    "                    neg_pair.update({tmp_pair_b:1})\n",
    "print(\"Finished test_neg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d09b3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608d68f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bcca5fe8",
   "metadata": {},
   "source": [
    "# Create train validation test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aaeb372",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_neg = pd.DataFrame(out_train_neg)\n",
    "df_train_neg.columns = [\"source\",\"target\"]\n",
    "df_valid_neg = pd.DataFrame(out_valid_neg)\n",
    "df_valid_neg.columns = [\"source\",\"target\"]  \n",
    "df_test_neg = pd.DataFrame(out_test_neg)\n",
    "df_test_neg.columns = [\"source\",\"target\"]  \n",
    "\n",
    "# train\n",
    "edges_train = np.array(pd.concat([df_train[[\"source\",\"target\"]],df_train_neg]))\n",
    "labels_train = [1 for _ in range(len(df_train))]\n",
    "labels_train.extend([0 for _ in range(len(df_train_neg))])\n",
    "labels_train = np.array(labels_train)\n",
    "\n",
    "# valid\n",
    "edges_valid = np.array(pd.concat([df_valid[[\"source\",\"target\"]],df_valid_neg]))\n",
    "labels_valid = [1 for _ in range(len(df_valid))]\n",
    "labels_valid.extend([0 for _ in range(len(df_valid_neg))])\n",
    "labels_valid = np.array(labels_valid)\n",
    "\n",
    "# test\n",
    "edges_test = np.array(pd.concat([df_test[[\"source\",\"target\"]],df_test_neg]))\n",
    "labels_test = [1 for _ in range(len(df_test))]\n",
    "labels_test.extend([0 for _ in range(len(df_test_neg))])\n",
    "labels_test = np.array(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cf844f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be88677b",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbefad4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('./tables/enron_staticlinkpred', \n",
    "         edges_train, labels_train,\n",
    "         edges_valid, labels_valid,\n",
    "         edges_test, labels_test,\n",
    "          df_node2cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab03959a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216421a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53d1875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e318c74b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6380e8be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a681fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae4566e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48522323",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
